# adversarial-components

A benchmarking suite aimed at measuring disentangled components of adversarial susceptibility.

See also https://robustbench.github.io/ for a similar work which focuses only on deep image classifier robustness.

# Libraries used

- [foolbox native](https://github.com/bethgelab/foolbox) and [torchattacks](https://pypi.org/project/torchattacks/) a  bases for adversarial example algorithms
- [timm](https://github.com/rwightman/pytorch-image-models) a.k.a. pytorch image models, as a basis for pretrained and robust models

